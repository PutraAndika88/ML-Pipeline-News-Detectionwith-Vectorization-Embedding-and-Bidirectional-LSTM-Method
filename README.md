# Submission 1: ML-Pipeline-News-Detection-with-Vectorization-Embedding-and-Bidirectional-LSTM-Method

Nama: Putra Andika Pradana

Username dicoding: puth88

| | Deskripsi |
| ----------- | ----------- |
| Dataset | [Fake News Detection](https://www.kaggle.com/datasets/jainpooja/fake-news-detection) |
| Masalah |Penyebaran informasi yang salah, terutama dalam bentuk "berita palsu", telah muncul sebagai tantangan sosial yang kritis di era informasi online yang ada di mana-mana. Narasi yang dibuat-buat atau menyesatkan ini sering kali menyamar sebagai berita yang sah, mengikis kepercayaan terhadap institusi media, memanipulasi opini publik, dan bahkan memengaruhi pemilihan umum. Kemampuan untuk secara otomatis mendeteksi dan menandai berita palsu telah menjadi tujuan yang semakin dicari oleh para peneliti dan praktisi pembelajaran mesin. Tugas ini muncul sebagai masalah klasifikasi yang kompleks, yang membutuhkan model untuk membedakan antara konten asli dan palsu berdasarkan pendekatan metode *Natural Language Processing* dengan *Vectorizing, Embedding, dan Bidirectional LSTM*.|
| Solusi machine learning | Berdasarkan permasalahan tersebut, dibutuhkan sebuah sistem yang dibangun dengan melibatkan sistem lain yaitu *deep learning* dimana *deep learning* adalah bagian dari *machine learning* yang mana mampu secara otomatis mendeteksi dan menandai berita palsu. Model *machine learning* ini setidaknya bermanfaat untuk pengguna yang terlibat aktif dan gemar dalam mengikuti sebuah isu seperti politik, ekonomi, teknologi, dan sebagainya untuk meminimalisir dari paparan informasi yang tidak benar dari berita yang kurang dapat dipercaya dari segi substansi|
| Metode pengolahan | Metode pengolahan data pada proyek ini yaitu pada *data validation* dilakukan proses *merger* dua dataset karena datanya terpisah. Kemudian, melakukan *feature engineering* dengan membuang *feature* yang tidak diperlukan pada proses pembuatan model seperti fitur tanggal dan judul berita karena yang dibutuhkan hanya isi dari berita saja. Selanjutnya, dilakukan proses tokenisasi isi teks berita agar menjadi bentuk angka yang dapat dimengerti oleh komputer. Pada *machine learning* pipeline ini, telah dilakukan beberapa proses yaitu *data ingestion* yang mana tahap ini mengerjakan beberapa tahapan untuk memastikan data yang masuk telah sesuai dan dapat diproses oleh komponen lain. Tahapan ini juga dianggap sebagai proses ETL (*extract, transform, load*) yang sederhana. Kemudian, *Data Validaation* yaitu memeriksa kualitas dan perubahan dari suatu data. Pada prosesnya, tahap ini akan memeriksa data baru dan membandingkannya dengan dataset yang digunakan dalam proses training (dataset sebelumnya atau training dataset). Selanjutnya, *Data Preprocessing* yaitu proses untuk mengubah (transform) suatu data ke dalam format yang lebih mudah diproses oleh mesin. Selanjutnya, *Model Development*, yaitu proses eksperimen dalam pembuatan arsitektur model yang cocok dengan data input dan tujuan yang ingin dicapai dengan menggunakan algoritma yang sesuai juga. Kemudian, yaitu tahap analisis dan validasi model yaitu mengevaluasi performa model menggunakan evaluation dataset dan memperhatikan metrik yang digunakan sebagai parameter.|
| Arsitektur model | Arsitektur model ini tersusun mulai dari *Text Vectorization*. *Layer* ini melakukan tugas pembersihan dan standarisasi teks seperti: memiringkan teks ke bawah dan ke atas, menghapus tanda baca dan karakter khusus, menormalkan spasi, *stemming* atau *lemmatization* (mengurangi kata menjadi bentuk dasarnya), menghentikan penghapusan kata (menghapus kata-kata umum dan tidak informatif). Kemudian, dilanjutkan dengan *Embedding layer* yang berfungsi untuk Transformasi, yaitu mengubah setiap kata menjadi vektor padat yang menangkap makna semantik dan hubungannya dengan kata lain. Hal ini memungkinkan model untuk memahami konteks dan nuansa bahasa jauh lebih baik daripada pengkodean satu kata yang sederhana yang mana menciptakan representasi yang jarang dan tidak efisien. Selanjutnya, arsitektur ini juga melibatkan *Bidirectional LSTM (Long-Short Term Memory) layer* yang mana memungkinkan model untuk menganalisis konteks setiap kata tidak hanya dari kata-kata sebelumnya, tetapi juga dari kata-kata setelahnya, sehingga memberikan pemahaman yang lebih komprehensif dari keseluruhan kalimat. Terakhir, adalah *dense layer* dengan satu neuron sebagai klasifikasi|
| Metrik evaluasi | Metric yang digunakan pada model yaitu *Binary Accuracy*, *True Positive*, *False Positive*, *True Negative*, *False Negative*, dan *AUC Curve* untuk mengevaluasi performa model dalam melakukan klasifikasi teks dari isi berita|
| Performa model | Model yang dibuat menghasilkan performa yang bagus dalam memberikan klasifikasi untuk teks isi sebuah berita, dan dari pelatihan yang dilakukan model menghasilkan *binary accuracy* dan *validation binary accuracy* sekitar 99% |
